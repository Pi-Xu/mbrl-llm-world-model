# @package _global_

defaults:
  - override /algo: llm_dreamer_S
  - override /env: dmc
  - override /model_manager: dreamer_v3
  - _self_

# Experiment
seed: 5

# Algorithm
algo:
  replay_ratio: 1
  total_steps: 500_000
  per_rank_batch_size: 4 # NOTE: edit this to suit cuda memory
  per_rank_sequence_length: 4
  # cnn_keys:
  #   encoder: [state]
  #   decoder: [state]
  mlp_keys:
    encoder: [state]
    decoder: [state]

fabric:
  accelerator: cuda

env:
  num_envs: 4
  action_repeat: 2
  max_episode_steps: -1
  # Wrapper to be instantiated
  wrapper:
    _target_: sheeprl.envs.dmc.DMCWrapper
    domain_name: cartpole
    task_name: swingup_sparse
    seed: 42
    from_pixels: False
    from_vectors: True


# Checkpoint
checkpoint:
  every: 100000

# Buffer
buffer:
  size: 500_000
  checkpoint: True
  memmap: True

# Distribution
distribution:
  type: "auto"

metric:
  log_every: 5000
  aggregator:
    metrics:
      Loss/world_model_loss:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Loss/value_loss:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Loss/policy_loss:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Loss/observation_loss:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Loss/reward_loss:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Loss/state_loss:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Loss/continue_loss:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      State/kl:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      State/post_entropy:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      State/prior_entropy:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Grads/world_model:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Grads/actor:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Grads/critic:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
